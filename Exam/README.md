# Breast Cancer ETL Pipeline

---

## Цель  проекта

Разработка воспроизводимого ETL-процесса для построения и оценки модели логистической регрессии, классифицирующей опухоли молочной железы как **злокачественные (malignant)** или **доброкачественные (benign)** на основе медицинских признаков. 

В качестве источника данных используется датасет **Breast Cancer Wisconsin Diagnostic** библиотеки `scikit-learn`. 

Оркестрация процесса реализована с помощью Apache Airflow.

---


## Планирование пайплайна

- **Тип задачи**: Бинарная классификация  
- **Модель**: Логистическая регрессия  
- **Цель**: Предсказание злокачественной (malignant) или доброкачественной (benign) опухоли  
- **Датасет**: `Breast Cancer Wisconsin Diagnostic Dataset` библиотеки `scikit-learn`

## Структура пайплайна

**1. `load_data`**
- Загрузка данных из библиотеки `sklearn.datasets`
- Сохранение в `data/raw_data.csv`

**2. `preprocess_data`**
- Чтение/обработка сырых данных
- Стандартизация признаков с помощью `StandardScaler`
- Разделение выборки на обучающую и тестовую
- Сохранение в `clean_data/preprocessed_data.csv`

**3. `train_model`**
- Обучение модели Логистической регрессии на обучающей выборке
- Сохранение модели в `results/model.pkl`

**4. `evaluate_model`**
- Прогнозирование и расчёт метрик (accuracy, precision, recall, f1-score)
- Сохранение результатов в `results/metrics.json`


##  Архитектура пайплайна

```text
    +-------------+
    |  load_data  | <-- Загрузка исходного CSV
    +------+------+
           |
           v
  +-----------------+
  | preprocess_data | <-- Очистка, стандартизация, кодирование
  +--------+-------+
           |
           v
    +-------------+
    | train_model | <-- Обучение Logistic Regression
    +------+------+
           |
           v
   +----------------+
   | evaluate_model | <-- Accuracy, Precision, Recall, F1, сохранение артефактов
   +----------------+
```
---

## Структура проекта
```text
project/
├── dag/
│   └── pipeline_dag.py
├── etl/
│   ├── __init__.py
│   ├── config.py
│   ├── logger_setup.py
│   ├── load_data.py
│   ├── preprocess_data.py
│   ├── train_model.py
│   └── evaluate_model.py
├── data/
│   ├── loaded_data.csv
│   └── preprocessed_data.csv
├── logs
│   ├── load_data.log
│   ├── evaluate_model.log
│   ├── preprocess_data.log
│   └── train_model.log
├── results/
│   ├── model.pkl
│   └── metrics.json
├── requirements.txt
└── README.md
```
---
## Структура и назначение скриптов

Проект состоит из набора Python-скриптов, каждый из которых отвечает за отдельный этап обработки данных и обучения модели. Скрипты находятся в папке `etl/` и выполняются последовательно в рамках DAG в Apache Airflow

1. `config.py` -  хранит пути к файлам и общие параметры конфигурации пайплайна
2. `load_data.py` - загружает датасет Breast Cancer из библиотеки `scikit-learn` и сохраняет исходные данные в `data/loaded_data.csv`
3. `preprocess_data.py` - загружает сырые данные, обрабатывает данные и разбивает на обучающую и тестовую выборки, сохраняет `data/preprocessed_data.csv`
4. `train_model.py` - обучает модель логистической регрессии и сохраняет её в `results/model.pkl`
5. `evaluate_model.py` - загружает модель и тестовые данные, рассчитывает и сохраняет отчёт в `results/metrics.json`
6. `logger.py` - настройки логгера
---

## DAG

DAG `breast_cancer_breast_cancer_etl_pipeline_pipeline` определён в файле: `dag/pipeline_dag.py`

---

## Зависимости между задачами

DAG состоит из 4 последовательно запускаемых задач:

1. `download_data` — загружает исходные данные
2. `preprocess_data` — выполняет очистку и масштабирование данных
3. `train_model` — обучает модель логистической регрессии
4. `evaluate_model` — рассчитывает метрики и сохраняет отчёт

---

## Запуск DAG вручную

Можно протестировать выполнение каждой отдельной задачи вручную с помощью CLI команды `airflow tasks test`. Пример:

```bash
# Протестировать загрузку данных:
airflow tasks test breast_cancer_ml_pipeline download_data 2025-06-17

# Протестировать обработку данных:
airflow tasks test breast_cancer_ml_pipeline preprocess_data 2025-06-17

# Обучение модели:
airflow tasks test breast_cancer_ml_pipeline train_model 2025-06-17

# Оценка модели:
airflow tasks test breast_cancer_ml_pipeline evaluate_model 2025-06-17
```

## Интеграция и хранение данных

Проект не использует внешние источники данных или API, не требует использования ключей доступа или переменных окружения. Весь процесс построен на локальной обработке датасета `Breast Cancer Wisconsin Diagnostic`, загружаемого из библиотеки `scikit-learn`. Таким образом, нет необходимости в ключах доступа, конфигурациях подключения или внешней авторизации.

---

## Анализ ошибок и устойчивости
 
- Повторный запуск: `retries=2` -  в случае неудачного выполнения задачи автоматически будет сделано до 2 повторных попыток, `retry_delay=timedelta(minutes=5)` - пауза между запусками составляет 5 минут
- Ограничение по времени выполнения: `execution_timeout=timedelta(minutes=15)` - в случае, если задача не завершится за 15 минут, она будет остановлена и помечена как failed
- Логирование: весь процесс логируется и логи доступны в папке logs/
- Обработка исключений: на всех ключевых этапах обрабатываются возможные исключения (Exception) 
- Robustness (устойчивость): Все задачи изолированы — сбой в одной не рушит остальные, возможна ручная отладка каждого скрипта

---

## Архитектура: отдельные модули

Каждый этап пайплайна оформлен как отдельный модуль внутри папки etl/, который запускается через `python -m etl.module_name`, что позволяет:
- Обеспечить изоляцию логики каждого этапа
- Упростить отладку и повторное использование кода


## Идеи по развитию проекта

- Поддержка нескольких моделей RandomForest, XGBoost, SVM
- Автоматическое оповещение через email/мессенджер
- Развёртывание в Docker, CI/CD, использование .env и config.yaml для параметров
- Интеграция с S3/Minio/Google Drive для хранения артефактов

---
